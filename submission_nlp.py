# -*- coding: utf-8 -*-
"""submission_NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ii2jR8JGIkh4-b7D1rPSRPTrZT6zRFDh

Nama  : Aida Muhdina
<br/>Email : aidamuhdina@gmail.com
"""

import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/Colab machine learning/Submission 1 NLP/bbc-text.csv')
df.head()

category = pd.get_dummies(df.category)
df = pd.concat([df, category], axis=1)
df = df.drop(columns='category')
df

news = df['text'].to_numpy()
label = df[['business', 'entertainment', 'politics', 'sport', 'tech']].to_numpy()

from sklearn.model_selection import train_test_split

news_latih, news_test, label_latih, label_test = train_test_split(news, label, test_size=0.2)

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=5000, oov_token='x')
tokenizer.fit_on_texts(news_latih)
tokenizer.fit_on_texts(news_test)

sekuens_latih = tokenizer.texts_to_sequences(news_latih)
sekuens_test = tokenizer.texts_to_sequences(news_test)

padded_latih = pad_sequences(sekuens_latih)
padded_test = pad_sequences(sekuens_test)

import tensorflow as tf

model = tf.keras.Sequential([
            tf.keras.layers.Embedding(input_dim=5000, output_dim=16),
            tf.keras.layers.LSTM(64),
            tf.keras.layers.Dense(64, activation='relu'),
            tf.keras.layers.Dropout(0.1),
            tf.keras.layers.Dense(5, activation='softmax')
])
model.compile(loss='categorical_crossentropy',
              optimizer='Adam',
              metrics=['accuracy'])

#membuat kelas callback untuk menghentikan training
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if logs.get('val_accuracy')>=0.90:
      self.model.stop_training = True
      accuracy = float(logs.get('accuracy'))*100
      val_accuracy = float(logs.get('val_accuracy'))*100
      print("reached %.2f%% accuracy and %.2f%% val_accuracy" %(accuracy, val_accuracy))

callback = myCallback()

num_epochs=30
history = model.fit(padded_latih, label_latih, epochs=num_epochs,
                    batch_size=128, validation_data=(padded_test, label_test),
                    verbose=2, callbacks=[callback])

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

#plot accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

#plot loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()